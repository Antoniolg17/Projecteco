{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examen Adelantado Econometr√≠a 2020-2021\n",
    "## 12 de Enero de 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Instrucciones\n",
    "\n",
    "+ La duraci√≥n del examen de 1.5 horas.\n",
    "+ Cada pregunta se responder√° en el recuadro bajo la pregunta, bien en modo s√≥lo texto (Preguntas 1 a 5) o bien en modo c√≥digos de Python + texto respuesta en base a los resultados obtenidos (Preguntas 6 a 10).\n",
    "+ Los datos necesarios est√° disponibles bien en la librer√≠a wooldridge o en el fichero Excel \"Pregunta7.xls\" que se encuentra en github (las √≥rdenes orientativas para leer los ficheros se encuentran descritas bajo cada uno de esos ejercicios).\n",
    "+ No se evaluar√°n respuestas en las que √∫nicamente haya c√≥digos. Los resultados deber√°n servir para responder a las preguntas.\n",
    "+ Las puntuaciones de cada ejercicio se encuentran en el propio enunciado.\n",
    "+ El fichero final del examen se enviar√° a v√≠a PRADO en la Tarea habilitada para el examen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### APELLIDOS,  NOMBRE: JOS√â LUIS GUID√ö NAVAS\n",
    "### DNI: 79146348J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 1: (1 punto)\n",
    "\n",
    "Justificar que $\\widehat{\\boldsymbol{\\beta}} \\sim N \\left( \\boldsymbol{\\beta}, \\ \\sigma^{2} \\cdot \\left( \\mathbf{X}^{t} \\mathbf{X} \\right)^{-1} \\right)$. ¬øQu√© supone este resultado cuando realizamos inferencia sobre los coeficientes de un modelo lineal m√∫ltiple?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Respuesta:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 2: (1 punto)\n",
    "\n",
    "Considera el modelo $Y_i = \\beta_0 + \\beta_1 X_i + u_i$ ($i=1,2,\\ldots,20$). Si realizamos la regresi√≥n de M√≠nimos Cuadrados Ordinarios de los residuos obtenidos en el modelo al cuadrado $u_i^2$ sobre las variables $X$ y $X^2$ (y la constante), obtenemos un $R^2$ de 0.35.  ¬øQu√© podemos decir sobre la homocedasticidad del modelo planteado?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Respuesta:\n",
    "\n",
    "Como el modelo no se ajusta bien a los datos dados debido a que el R^2 es un valor bajo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 3: (0.75 puntos)\n",
    "\n",
    "Enumerar y describir brevemente la hip√≥tesis b√°sicas necesarias para realizar el an√°lisis de un\n",
    "modelo de regresi√≥n lineal m√∫ltiple. Justificar las razones por las que se exigen cada una de\n",
    "estas hip√≥tesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Respuesta:\n",
    "\n",
    "Hip√≥tesis b√°sicas sobre el modelo:\n",
    "‚ú† El supuesto de linealidad. Nos deja utilizar procedimientos algebraicos sobre matrices y vectores simplificando su operatoria.\n",
    "‚ú† El supuesto rango completo por columnas: En el caso de que no se verifique habr√≠a problema de multicolinealidad.\n",
    "el supuesto mencionado, implicar√≠a que alguna de las variables explicativas ser√≠a combinaci√≥n lineal de otras de las variables, produci√©ndose un problema de multicolinealidad.\n",
    "‚ú† El supuesto de exogeneidad. Si el valor esperado de la perturbaci√≥n es cero.\n",
    "‚ú† El supuesto de causalidad. El mecanismo de generaci√≥n de las observaciones.\n",
    "‚ú† Supuestos sobre el t√©rmino perturbaci√≥n. Nos deja saber si estamos ante un problema de heterocedasticidad o de\n",
    "multicolinealidad.\n",
    "‚ú† El supuesto de normalidad del t√©rmino de perturbaci√≥n. Realiza una inferencia sobre los par√°metros que intervienen en el modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 4: (0.5 puntos)\n",
    "\n",
    "En el caso de tener que decidir qu\\'e modelo es el mejor en el siguiente caso:\n",
    "        \\begin{eqnarray*}\n",
    "            \\mbox{Modelo 1: } & & \\mathbf{Y} = \\beta_{1} + \\beta_{2} \\cdot \\mathbf{X}_{2} + \\beta_{3} \\cdot \\mathbf{X}_{3} + \\mathbf{u}. \\\\\n",
    "            \\mbox{Modelo 2: } & & \\mathbf{Y} = \\alpha_{1} + \\alpha_{2} \\cdot \\mathbf{X}_{2} + \\alpha_{3} \\cdot \\mathbf{X}_{3} + \\alpha_{4} \\cdot \\mathbf{X}_{4} + \\mathbf{v}.\n",
    "        \\end{eqnarray*}\n",
    "        ¬øQu√© herramientas usar√≠a y con qu√© criterios? Justifique su respuesta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Respuesta:\n",
    "\n",
    "Tendr√≠amos que calcular el AIC y el BIC de ambos modelos. Una vez calculados nos fijaremos en que modelo tiene el AIC y el BIC mas bajo. El modelo cuyo AIC y BIC fuese inferior, ser√≠a el mejor modelo. Se usa esta herramienta porque otras herramientas de ajuste como el R^2 no tienen en cuenta el n√∫mero de variables por ejemplo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 5: (0.75 puntos)\n",
    "\n",
    "Consideremos un modelo econ√≥mico en el que se desea explicar el precio de la vivienda en funci√≥n de la zona donde se encuentra la vivienda, sus metros cuadrados, n√∫mero de habitaciones, n√∫mero de ba√±os y si tiene o no cochera. Puesto que se sospecha que pudieran existir relaciones lineales entre los metros cuadrados de la vivienda y el n√∫mero de ba√±os y habitaciones de la misma, se calcula el factor de inflaci√≥n de la varianza, obteni√©ndose que el mayor de ellos es igual a 4.78. ¬øSe puede decir que el grado de multicolinealidad aproximada existente es preocupante? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Respuesta:\n",
    "No, la multicolinealidad no es preocupante ya que el FIV es menor a 10.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 6: (1.5 puntos)\n",
    "\n",
    "Se desea analizar el n√∫mero de becarios en la ense√±anza universitaria, $\\mathbf{B}$ (medidos en miles), a partir del n√∫mero de alumnos matriculados en los estudios de primer y segundo ciclo, $\\mathbf{A}$ (medidos en miles), y el importe destinado a becas, $\\mathbf{I}$ (medido en millones de euros). A partir de las universidades de las 17 comunidades aut√≥nomas m√°s la universidad a distancia, se obtiene:\n",
    "        $$(\\mathbf{X}^{t} \\mathbf{X})^{-1} =  \\begin{pmatrix} 0.114 & -0.0005 & -0.0002 \\\\ -0.0005 & 0.00002 & -0.00002 \\\\ -0.0002 & -0.00002 & 0.00003 \\end{pmatrix}, \\mathbf{X}^{t} \\mathbf{y} = \n",
    "            \\begin{pmatrix}\n",
    "                443.818 \\\\\n",
    "         66792.89 \\\\\n",
    "                53125.748\n",
    "            \\end{pmatrix}, \\mathbf{y}^{t} \\mathbf{y} = 21953.5,$$\n",
    "            \n",
    "Se pide responder de forma razonada las siguientes cuestiones:\n",
    "1. Especificar los modelos econ√≥mico y econom√©trico.\n",
    "1. Obtener la estimaci√≥n de los coeficientes del modelo.\n",
    "1. ¬øEs el coeficiente del n√∫mero de alumnos matriculados en los estudios de primer y segundo ciclo significativamente distinto de cero al 95% de confianza? Indique las consecuencias del an√°lisis realizado.\n",
    "1. Es el coeficiente del importe destinado a becas significativamente distinto de cero al 5% de significaci√≥n? Indique las consecuencias del an√°lisis realizado.\n",
    "1. Es el modelo globalmente significativo? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C√°lculos:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Respuesta:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 7: (1.5 puntos)\n",
    "\n",
    "Se considera el modelo econom√©trico $Y_i = \\beta_0 X_i^{\\beta_1} X_2^{\\beta_2} {\\rm exp}({u_i})$ $i=1, \\ldots, n$, donde $Y$ es la producci√≥n total de un bien, $X_1$ es el stock de capital, $X_2$ es el n√∫mero de empleados para producir el bien y $u_i$ es la perturbaci√≥n aleatoria. \n",
    "1. Transforma el modelo anterior en un modelo lineal m√∫ltiple.\n",
    "1. ¬øC√≥mo se interpretar√≠an los coeficientes del modelo? \n",
    "1. Que sentido tendr√≠a que $\\beta_1+\\beta_2=1$.\n",
    "1. Estima el modelo para los datos de \"Pregunta7.xls\", interpreta los coeficientes obtenidos y comprueba si $\\beta_1+\\beta_2=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'statsmodels.stats.contrast.ContrastResults'>\n",
       "<F test: F=array([[0.19558359]]), p=0.6628307009410124, df_denom=21, df_num=1>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#C√°lculos:\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "datos7 = pd.read_excel (\"Pregunta7.xls\")\n",
    "#print(datos7)\n",
    "\n",
    "#Tomamos logaritmos\n",
    "datos7[\"lY\"] = np.log(datos7[\"Y\"])\n",
    "datos7[\"lX1\"] = np.log(datos7[\"X1\"])\n",
    "datos7[\"lX2\"] = np.log(datos7[\"X2\"])\n",
    "\n",
    "y=datos7[\"lY\"]\n",
    "X=datos7[[\"lX1\",\"lX2\"]]\n",
    "\n",
    "mco7=sm.OLS(y, sm.add_constant(X)).fit()\n",
    "mco7.summary()\n",
    "\n",
    "#Para realizar tests de hipotesis R*B=r\n",
    "mco7.f_test(([0,1,1],1))\n",
    "#Al no poder rechazar la hip. nula porque el p-valor es m√°s grande que 0.05. Damos por valido que ùõΩ1+ùõΩ2=1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Respuesta:\n",
    "Lo transformamos en lineal m√∫ltiple tomando logaritmos.\n",
    "Yi = B0 * Xi^B1 * X2^B2 * exp(ui)\n",
    "log(Yi) = log(B0 * Xi^B1 * X2^B2 * exp(ui))\n",
    "log(Yi) = log(B0) + log(Xi^B1) + log(X2^B2) + log(exp(ui))\n",
    "log(Yi) = log(B0) + B1*log(Xi) + B2*log(X2) + ui\n",
    "\n",
    "Al tener log en ambos miembros: Un aumento de un 1% de la X afecta un beta% a la Y.\n",
    "\n",
    "Si la suma de los beta es 1, un incremento conjunto de los X de 1% aumenta un 1% la Y\n",
    "\n",
    "Sabiendo que ùëå  es la producci√≥n total de un bien, ùëã1 es el stock de capital, ùëã2 es el n√∫mero de empleados para producir el bien, observando el estudio del modelo podemos ver como es globalmente significativo con un p-valor inferior a 0.05. Tambi√©n son significativas individualmente lX1 y lX2 por el p-valor inferior a 0.05. Dir√≠amos que un 1% de variaci√≥n en X1 aumenta 0.2331% la Y, lo mismo con X2 pero con un incremento del 0.8073%.\n",
    "Despu√©s de realizar el test de hip√≥tesis, al no poder rechazar la hip. nula porque el p-valor es m√°s grande que 0.05. Damos por valido que ùõΩ1+ùõΩ2=1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 8: (1 punto)\n",
    "\n",
    "En la base de datos $\\texttt{phillips}$ se encuentra informaci√≥n para analizar el efecto del desempleo (unem) en el IPC (inf) desde 1948 a 2003. Estima el modelo lineal simple y estudia la existencia de autocorrelaci√≥n en √©ste. En caso afirmativo, aplica alguna estrategia para corregirla y comprueba si ha concluido con √©xito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>GLSAR Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>inf</td>       <th>  R-squared:         </th> <td>   0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLSAR</td>      <th>  Adj. R-squared:    </th> <td>   0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   5.436</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 12 Jan 2021</td> <th>  Prob (F-statistic):</th>  <td>0.0236</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:25:14</td>     <th>  Log-Likelihood:    </th> <td> -118.95</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    55</td>      <th>  AIC:               </th> <td>   241.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    53</td>      <th>  BIC:               </th> <td>   245.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    7.3837</td> <td>    2.224</td> <td>    3.321</td> <td> 0.002</td> <td>    2.924</td> <td>   11.844</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>unem</th>  <td>   -0.6850</td> <td>    0.294</td> <td>   -2.331</td> <td> 0.024</td> <td>   -1.274</td> <td>   -0.096</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 9.225</td> <th>  Durbin-Watson:     </th> <td>   1.626</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.010</td> <th>  Jarque-Bera (JB):  </th> <td>  19.725</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.230</td> <th>  Prob(JB):          </th> <td>5.21e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.897</td> <th>  Cond. No.          </th> <td>    12.0</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           GLSAR Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                    inf   R-squared:                       0.093\n",
       "Model:                          GLSAR   Adj. R-squared:                  0.076\n",
       "Method:                 Least Squares   F-statistic:                     5.436\n",
       "Date:                Tue, 12 Jan 2021   Prob (F-statistic):             0.0236\n",
       "Time:                        10:25:14   Log-Likelihood:                -118.95\n",
       "No. Observations:                  55   AIC:                             241.9\n",
       "Df Residuals:                      53   BIC:                             245.9\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          7.3837      2.224      3.321      0.002       2.924      11.844\n",
       "unem          -0.6850      0.294     -2.331      0.024      -1.274      -0.096\n",
       "==============================================================================\n",
       "Omnibus:                        9.225   Durbin-Watson:                   1.626\n",
       "Prob(Omnibus):                  0.010   Jarque-Bera (JB):               19.725\n",
       "Skew:                          -0.230   Prob(JB):                     5.21e-05\n",
       "Kurtosis:                       5.897   Cond. No.                         12.0\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#C√°lculos:\n",
    "\n",
    "from wooldridge import *\n",
    "datos8=dataWoo(\"phillips\")\n",
    "\n",
    "#C√°lculos:\n",
    "\n",
    "from wooldridge import *\n",
    "import statsmodels.api as sm\n",
    "datos8=dataWoo(\"phillips\")\n",
    "\n",
    "Y=datos8[\"inf\"] #la variable endogena ser√° la columna sinf\n",
    "X=sm.add_constant(datos8[\"unem\"]) #a√±adimos constante a las variables exogenas\n",
    "\n",
    "mco8=sm.OLS(Y, X).fit()  #ajustamos el modelo \n",
    "mco8.summary()  #resumen del modelo ajustado\n",
    "\n",
    "#realizamos el contraste de durbin watson\n",
    "from statsmodels.stats.stattools import durbin_watson \n",
    "dw=durbin_watson(mco8.resid)\n",
    "dw    #dw es igual a 0.80 por lo que hay presencia de correlacion positiva\n",
    "\n",
    "#corregimos el modelo con la modificaci√≥n Prais-Winsten\n",
    "rho= 1 - dw/2\n",
    "\n",
    "mco8_autocorr=sm.GLSAR(Y, sm.add_constant(X), rho=rho).iterative_fit(maxiter=1000)\n",
    "mco8_autocorr.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Respuesta:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Respuesta: \n",
    "El modelo lineal simpre es IPC = 1.0536 + 0.05024*UNEM. Podemos afirmar la presencia de autocorrelacion positiva\n",
    "ya que el contraste de Durbin-Watson nos da 0,801 que es cercano a 0. Aplicamos la modificacion de Prais-Winsten para corregirlo.\n",
    "El nuevo modelo tiene un DW de 1.626 que esta mucho m√°s cercano a 2 habiendo eliminado parte de la autocorrelacion.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 9: (1 punto)\n",
    "\n",
    "Comprueba la existencia de heteroscedasticidad en el modelo $\\log(price) = \\beta_0+ \\beta_1 \\log(lotsize)+\\log(sqrft)+bdrms$ usando los datos de $\\texttt{hprice1}$ utilizando el test de Breush-Pagan. ¬øQu√© consecuencias tendr√≠a en el an√°lisis del modelo su existencia?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LM Statistic': 4.223248117304362, 'LM-Test p-value': 0.2383445905811877, 'F-Statistic': 1.411500740087146, 'F-Test p-value': 0.24514541735245635}\n"
     ]
    }
   ],
   "source": [
    "#C√°lculos:\n",
    "\n",
    "from wooldridge import *\n",
    "datos9=dataWoo(\"hprice1\")\n",
    "#datos9=dataWoo(\"hprice1\", description=True)\n",
    "\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "from statsmodels.stats.diagnostic import het_white\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd #librer√≠a para manejo de datos\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "\n",
    "y = datos9['lprice'] #Nota final es la variable end√≥gena (la que quiero explicar)\n",
    "X = datos9[['llotsize', 'lsqrft', 'bdrms']] #Variables ex√≥genas\n",
    "\n",
    "\n",
    "results = sm.OLS(y,sm.add_constant(X)).fit()\n",
    "\n",
    "#Test de Breusch-Pagan\n",
    "bp_test = het_breuschpagan(results.resid, results.model.exog)\n",
    "\n",
    "labels = ['LM Statistic', 'LM-Test p-value', 'F-Statistic', 'F-Test p-value']\n",
    "print(dict(zip(labels, bp_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Respuesta:\n",
    "Procederemos a utilizar el test de **Breusch-Pagan**. Este test estudia si la variaza de los residuos depende de las variables independientes.\n",
    "$$e^2 = \\delta_1 x_1+ ... + \\delta_p X_p+u$$\n",
    "por lo que contrasta la hip√≥tesis nula:\n",
    "$$H_0:\\delta_1=\\delta_2=...=0$$\n",
    "Si se rechaza la hip√≥tesis nula existe heterocedasticidad.\n",
    "\n",
    "Si el p-valor es superior a nuestro alpha=0.05 (lo es) entonces no podemos rechazar nuestra hipotesis nula y afirmamos la presencia de homocedasticidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 10: (1 punto)\n",
    "\n",
    "Se pretende analizar el efecto de los ingresos per c√°pita (pcinc), de la poblaci√≥n (popul) y del n√∫mero de m√©dicos por cada 100 mil habitantes (physic) en la mortalidad infantil (infmrt), medida como el n√∫mero de muertes infantiles por cada mil nacimientos vivos.\n",
    "1. Usando la base de datos $\\texttt{infmrt}$ para 1990, estima el modelo econom√©trico lineal usando los logaritmos de las variables ex√≥genas e interpreta los resultados obtenidos.\n",
    "2. Analiza si existen diferencias significativas entre los resultados obtenidos para 1990 y para los de 1987."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                infmort   R-squared:                       0.182\n",
      "Model:                            OLS   Adj. R-squared:                  0.157\n",
      "Method:                 Least Squares   F-statistic:                     7.260\n",
      "Date:                Tue, 12 Jan 2021   Prob (F-statistic):           0.000190\n",
      "Time:                        10:28:36   Log-Likelihood:                -207.70\n",
      "No. Observations:                 102   AIC:                             423.4\n",
      "Df Residuals:                      98   BIC:                             433.9\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         36.2261     10.135      3.574      0.001      16.114      56.338\n",
      "lpcinc        -4.8841      1.293     -3.777      0.000      -7.450      -2.318\n",
      "lpopul        -0.0536      0.187     -0.286      0.776      -0.426       0.318\n",
      "lphysic        4.0278      0.891      4.521      0.000       2.260       5.796\n",
      "==============================================================================\n",
      "Omnibus:                       28.943   Durbin-Watson:                   0.805\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               64.358\n",
      "Skew:                           1.062   Prob(JB):                     1.06e-14\n",
      "Kurtosis:                       6.261   Cond. No.                         745.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "0.03325813331481752 2.4674936234496485\n"
     ]
    }
   ],
   "source": [
    "#C√°lculos:\n",
    "\n",
    "from wooldridge import *\n",
    "datos10=dataWoo(\"infmrt\")\n",
    "\n",
    "#C√°lculos:\n",
    "import numpy as np\n",
    "from wooldridge import *\n",
    "datos10=dataWoo(\"infmrt\")\n",
    "\n",
    "\n",
    "datos10[\"lpcinc\"]=np.log(datos10[\"pcinc\"])\n",
    "datos10[\"lpopul\"]=np.log(datos10[\"popul\"])\n",
    "datos10[\"lphysic\"]=np.log(datos10[\"physic\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Y=datos10['infmort'] #la variable endogena ser√° la columna infmort\n",
    "X=sm.add_constant(datos10[['lpcinc', 'lpopul','lphysic']]) #a√±adimos constante a las variables exogenas\n",
    "\n",
    "mco10=sm.OLS(Y, X).fit()  #ajustamos el modelo \n",
    "print(mco10.summary())  #resumen del modelo ajustado\n",
    "SCR=mco10.ssr  #SCR del total de los datos\n",
    "\n",
    "#realizamos el test de Chow\n",
    "\n",
    "datos1987=datos10[datos10[\"year\"]==1987]  #modelo para 1987\n",
    "Y1987=datos1987[\"infmort\"]\n",
    "X1987=datos1987[[\"lpcinc\", \"lpopul\", \"lphysic\"]]\n",
    "mco1987=sm.OLS(Y1987, sm.add_constant(X1987)).fit()\n",
    "SCR1987=mco1987.ssr\n",
    "\n",
    "\n",
    "datos1990=datos10[datos10[\"year\"]==1990]  #modelo para 1990\n",
    "Y1990=datos1990[\"infmort\"]\n",
    "X1990=datos1990[[\"lpcinc\", \"lpopul\", \"lphysic\"]]\n",
    "mco1990=sm.OLS(Y1990, sm.add_constant(X1990)).fit()\n",
    "SCR1990=mco1990.ssr\n",
    "\n",
    "\n",
    "n=len(datos10) \n",
    "k=3 #numero variables\n",
    "\n",
    "Fexp=(n-2*k-2)/(k+1) * (SCR - (SCR1987+SCR1990))/(SCR1987+SCR1990)\n",
    "Fexp\n",
    "\n",
    "from scipy import stats\n",
    "Fteo= stats.f.ppf(1-0.05, k+1, n-2*k-1)\n",
    "\n",
    "print(Fexp, Fteo) #se rechaza que 1990 y 1987 son iguales si Fexp>Fteo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Respuesta:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo es globalmente significativo con un p-valor inferior a 0.05, las variables son significativas salvo lpopul que tiene un pvalor de 0.776. \n",
    "\n",
    "Un incremento del 1% en la variable pcinc hace que la Y aumente en -4.8841 unidades, si aumenta pcinc, la Y (mortalidad infantil) disminuye. \n",
    "\n",
    "Aunque no siendo logpopul significativa, un aumento del 1% en la variable popul har√° que la Y aumente en -0.0536 unidades, si aumenta, la mortalidad infantil disminuir√°. \n",
    "\n",
    "Un aumento del 1% en la variable pcinc har√° que la Y aumente en 4.0278 unidades, si aumenta, la Y (mortalidad infantil) aumenta \n",
    "tambien, cabr√≠a destacar la paradoja que aparantemente es que cuantos m√°s m√©dicos m√°s mortalidad infantil.\n",
    "\n",
    "2)Realizamos el test de Chow:\n",
    "La hipotesis nula es que la regresion lineal de la mortalidad de ambos a√±os es la misma, obteniendo un Fexp=0,0332 y Fteo=2,467. Como Fexp<Fteorica no rechazamos la hipotesis nula. Por lo que podemos afirmar con una seguridad del 95% que no existen diferencias entre ambos a√±os."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
